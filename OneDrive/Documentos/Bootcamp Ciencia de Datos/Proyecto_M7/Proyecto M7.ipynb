{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 7 Bootcamp de Ciencia de Datos e Inteligencia Artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis y preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     App                                  Translated_Review  \\\n",
      "0  10 Best Foods for You  I like eat delicious food. That's I'm cooking ...   \n",
      "1  10 Best Foods for You    This help eating healthy exercise regular basis   \n",
      "2  10 Best Foods for You                                                NaN   \n",
      "3  10 Best Foods for You         Works great especially going grocery store   \n",
      "4  10 Best Foods for You                                       Best idea us   \n",
      "\n",
      "  Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \n",
      "0  Positive                1.00                0.533333  \n",
      "1  Positive                0.25                0.288462  \n",
      "2       NaN                 NaN                     NaN  \n",
      "3  Positive                0.40                0.875000  \n",
      "4  Positive                1.00                0.300000  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64295 entries, 0 to 64294\n",
      "Data columns (total 5 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   App                     64295 non-null  object \n",
      " 1   Translated_Review       37427 non-null  object \n",
      " 2   Sentiment               37432 non-null  object \n",
      " 3   Sentiment_Polarity      37432 non-null  float64\n",
      " 4   Sentiment_Subjectivity  37432 non-null  float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 2.5+ MB\n",
      "None\n",
      "App                           0\n",
      "Translated_Review         26868\n",
      "Sentiment                 26863\n",
      "Sentiment_Polarity        26863\n",
      "Sentiment_Subjectivity    26863\n",
      "dtype: int64\n",
      "                                   Translated_Review Sentiment\n",
      "0  I like eat delicious food. That's I'm cooking ...  Positive\n",
      "1    This help eating healthy exercise regular basis  Positive\n",
      "3         Works great especially going grocery store  Positive\n",
      "4                                       Best idea us  Positive\n",
      "5                                           Best way  Positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "df = pd.read_csv('googleplaystore_user_reviews.csv')\n",
    "\n",
    "# Visualizar las primeras filas del dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Información del dataframe\n",
    "print(df.info())\n",
    "\n",
    "# Verificar valores faltantes\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Eliminar filas con valores faltantes\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Filtrar solo las columnas necesarias (Texto de la reseña y Sentimiento)\n",
    "df = df[['Translated_Review', 'Sentiment']]\n",
    "\n",
    "# Visualizar las primeras filas después del filtrado\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nrubi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nrubi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nrubi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Descargar recursos de NLTK\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Función para preprocesar el texto\n",
    "def preprocess_text(text):\n",
    "    # Convertir texto a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar caracteres no alfabéticos\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Tokenizar el texto\n",
    "    tokens = word_tokenize(text)\n",
    "    # Eliminar palabras vacías (stopwords)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lematizar las palabras\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Unir tokens en una sola cadena\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "# Aplicar la función de preprocesamiento al conjunto de datos\n",
    "df['Preprocessed_Review'] = df['Translated_Review'].apply(preprocess_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.90      0.41      0.57      1653\n",
      "     Neutral       0.85      0.09      0.17      1049\n",
      "    Positive       0.71      0.99      0.83      4784\n",
      "\n",
      "    accuracy                           0.74      7486\n",
      "   macro avg       0.82      0.50      0.52      7486\n",
      "weighted avg       0.77      0.74      0.68      7486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X = df['Preprocessed_Review']\n",
    "y = df['Sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorizar el texto usando TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# Entrenar un clasificador Naive Bayes\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_vect, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = nb_classifier.predict(X_test_vect)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentimiento predicho para 'This app is amazing! It works perfectly and has great features.': Positivo\n",
      "Probabilidad de la clase 'Positive': 98.30%\n"
     ]
    }
   ],
   "source": [
    "# Prueba del modelo Naive Bayes\n",
    "#---------------------------------------------------\n",
    "test_text = \"This app is amazing! It works perfectly and has great features.\"\n",
    "\n",
    "# Preprocesar el texto de prueba\n",
    "preprocessed_test_text = preprocess_text(test_text)\n",
    "\n",
    "# Vectorizar el texto de prueba\n",
    "test_text_vectorized = vectorizer.transform([preprocessed_test_text])\n",
    "\n",
    "# Realizar la predicción\n",
    "predicted_label = nb_classifier.predict(test_text_vectorized)[0]\n",
    "\n",
    "# Mapear las etiquetas predichas a los sentimientos\n",
    "sentiment_mapping = {\n",
    "    'Negative': 'Negativo',\n",
    "    'Positive': 'Positivo',\n",
    "    'Neutral': 'Neutral'\n",
    "}\n",
    "\n",
    "predicted_sentiment = sentiment_mapping.get(predicted_label, \"Desconocido\")\n",
    "print(\"Sentimiento predicho para '{}': {}\".format(test_text, predicted_sentiment))\n",
    "\n",
    "# Calcular la probabilidad de cada clase para el texto de prueba\n",
    "probabilities = nb_classifier.predict_proba(test_text_vectorized)[0]\n",
    "\n",
    "# Obtener la probabilidad de la clase \"Positive\"\n",
    "positive_probability = probabilities[nb_classifier.classes_ == \"Positive\"][0]\n",
    "\n",
    "# Imprimir la probabilidad de la clase \"Positive\"\n",
    "print(\"Probabilidad de la clase 'Positive': {:.2%}\".format(positive_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(nb_classifier, 'sentiment_analysis_model.pkl')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
